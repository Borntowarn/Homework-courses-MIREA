{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **Задача 1**. Посчитайте количество обучаемых параметров в сети net_seq и net_model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(3 + 1) * 5 + (5 + 1) * 2 = 32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P9bWaC9QQJm"
      },
      "source": [
        "## **Задача 2**. Cделать нейрон, соответствующий оператору НЕ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Hh8sSJkEWNmT"
      },
      "outputs": [],
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r9HoH1koVQXi"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-0.1091]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.7349], requires_grad=True))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MLmGhtWFTYlV"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[-1.]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.1000], requires_grad=True))"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neuron.fc.weight.data = torch.tensor([[-1.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.1])\n",
        "neuron.fc.weight, neuron.fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UFr5InkDTf-r"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([1.0])\n",
        "neuron(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRxJxcRJQsMz"
      },
      "source": [
        "## **Задача 3**. Cделать нейрон, соответствующий оператору И."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7dvDtA7HX3V6"
      },
      "outputs": [],
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olMqAnQtX5NQ",
        "outputId": "a831cba3-c482-4e38-f2de-232eea4fe04f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Parameter containing:\n",
              " tensor([[ 0.5424, -0.4504]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([0.0197], requires_grad=True))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neuron = Neuron()\n",
        "neuron.fc.weight, neuron.fc.bias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kAtwMX7HQ0aj"
      },
      "outputs": [],
      "source": [
        "neuron.fc.weight.data = torch.tensor([[1., 1.]])\n",
        "neuron.fc.bias.data = torch.tensor([-1.5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "P27EdNkrXloh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.]], grad_fn=<NotImplemented>)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([[0.0, 0.0],\n",
        "                  [0.0, 1.0],\n",
        "                  [1.0, 0.0],\n",
        "                  [1.0, 1.0],])\n",
        "print(neuron(x))\n",
        "assert neuron(x).flatten().tolist() == [0,0,0,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRuSrP7JQ00i"
      },
      "source": [
        "## **Задача 4**. Cделать нейрон, соответствующий оператору ИЛИ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "23RuhFqbQ24-"
      },
      "outputs": [],
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.5, 0.5]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "i-BZHFqnXpLL"
      },
      "outputs": [],
      "source": [
        "x = torch.tensor([[0.0, 0.0],\n",
        "                  [0.0, 1.0],\n",
        "                  [1.0, 0.0],\n",
        "                  [1.0, 1.0],])\n",
        "assert neuron(x).flatten().tolist() == [0,1,1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b95Z8u7Q3OL"
      },
      "source": [
        "## **Задача 5**. Cделать нейрон, соответствующий оператору XOR."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hWP7ee7tjCGv"
      },
      "outputs": [],
      "source": [
        "neuron.fc.weight.data = torch.tensor([[0.0, 0.0]])\n",
        "neuron.fc.bias.data = torch.tensor([0.0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HgDrZ7PBjGwJ"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.], grad_fn=<NotImplemented>)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.tensor([0.0, 0.0])\n",
        "neuron(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiPV2u5zfwyo"
      },
      "source": [
        "## **Вопрос 1**. Какие нейронные сети могут иметь только линейную разделяющую поверхность?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNi4IwB8f9yK"
      },
      "source": [
        "Имеющие линейную функцию активации"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEf1aXsdgLBh"
      },
      "source": [
        "## **Вопрос 2**. Имеет ли смысл соединять полносвязанные нейроны (нейроны, которые принимают на вход все выходы предыдущего слоя) с линейной функцией активации в многослойную нейронную сеть?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy06MWy-gQCh"
      },
      "source": [
        "Нет, так как коэффициенты будут просто накапливаться в линейной размерности"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJ9Uxo7DEns4"
      },
      "source": [
        "# **Домашнее задание**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hbaklz_96EN"
      },
      "source": [
        "Дедлайн домашнего задания - текущее воскресенье 23:59. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7VzrzlHyyci"
      },
      "source": [
        "# **Домашнее задание 0:** \n",
        "Создайте репозиторий на Github. Вся дальнейшая домашка загружается туда. Чуть позже в телеграм чате будет выложена форма для сдачи."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "me6riR-YEuYg"
      },
      "source": [
        "# **Домашнее задание 1:** \n",
        "Реализуйте XOR с помощью 3 нейронов. Запишите ответ в виде выражения, состоящего из объектов neuron() – моделей нейрона с пороговой функцией активации, внутри скобок может быть что угодно. Входы верхнего уровня называются x1 и x2. Пример фрагмента записи: neuron(1*x1 + 5*x2 - 0.1) + neuron(x1) (ответ будет выглядеть чуть сложнее, но других символов вроде && не потребуется)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "xor = neuron(neuron(-x1 - x2 + 1.5) + neuron (0.5x1 + 0.5x2) - 1.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Проверка:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Neuron(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc = torch.nn.Linear(2, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return torch.heaviside(self.fc(x), torch.tensor([0.0]))\n",
        "\n",
        "neuron = Neuron()\n",
        "x = torch.tensor([[0.0, 0.0],\n",
        "                  [0.0, 1.0],\n",
        "                  [1.0, 0.0],\n",
        "                  [1.0, 1.0],])\n",
        "\n",
        "neuron.fc.weight.data = torch.Tensor([[-1, -1]])\n",
        "neuron.fc.bias.data = torch.Tensor([[1.5]])\n",
        "n1 = neuron(x)\n",
        "\n",
        "neuron.fc.weight.data = torch.Tensor([[0.5, 0.5]])\n",
        "neuron.fc.bias.data = torch.Tensor([[0]])\n",
        "n2 = neuron(x)\n",
        "\n",
        "neuron.fc.weight.data = torch.Tensor([[1, 1]])\n",
        "neuron.fc.bias.data = torch.Tensor([[-1.5]])\n",
        "n3 = neuron(torch.cat((n1, n2), 1))\n",
        "\n",
        "assert n3.flatten().tolist() == [0,1,1,0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQmVNc2kEyQP"
      },
      "source": [
        "# **Домашнее задание 2:** \n",
        "Нарисуйте backward граф для выражения `a*b+c*d`. [Теория и пример оформления](https://www.youtube.com/watch?v=MswxJw-8PvE). Сравните полученные теоретические значения с аттрибутами grad у исходных тензоров."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Image alt](%D0%B3%D1%80%D0%B0%D1%84%20%D0%B1%D1%8D%D0%BA.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rHAT-rNxnh-X"
      },
      "outputs": [],
      "source": [
        "a = torch.tensor([2.0], requires_grad=True)\n",
        "b = torch.tensor([4.0], requires_grad=True)\n",
        "c = torch.tensor([1.0], requires_grad=True)\n",
        "d = torch.tensor([5.0], requires_grad=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQUF6a8rnjyF",
        "outputId": "230bb851-c97d-4862-8667-9e3d7cde79cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(a.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WQewq5DCnnPF"
      },
      "outputs": [],
      "source": [
        "loss = a*b + c*d\n",
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDxWZCwQnojN",
        "outputId": "84189f95-a7d5-4d57-a1be-0fa1329024dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([2.])\n"
          ]
        }
      ],
      "source": [
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxKEOwWDwv3Y"
      },
      "source": [
        "# **Домашнее задание 3:** \n",
        "Поэксперементируйте с размером тензоров, которые влезут на видеоркарту в Colab. Найдите максимальный размер тензора для типа данных float32, float64, float16, int32, int64. На сколько они отличаются."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cbJTJaglSjWC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ZUkQe6X59t",
        "outputId": "5cb760bb-18f8-49ef-9884-fe7eb3af68de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 30 16:44:11 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    27W /  70W |    610MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "hOHRYTL2Ygeo"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "del a\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulLIAzohaiwN",
        "outputId": "f3c3a978-e927-4ae9-86a2-0da5b61c7705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "15091105792"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.memory_reserved()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU1Ytlj2bOvx",
        "outputId": "278c456b-7896-4b90-d0d4-414777012181"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.memory_allocated()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPIIJnbtd1Cj"
      },
      "source": [
        "Максимум для float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "hIJAsZiAbavc"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros(4096, 927872, dtype=torch.float32,device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9xnhbvWbtqY",
        "outputId": "38c4aa71-d681-4a9b-eca6-6972a5f255be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 30 16:55:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P0    28W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcMf4-xjd-S9"
      },
      "source": [
        "Максимум для float64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "pxn7C5n6eFTi"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros(4096, 927872//2, dtype=torch.float64,device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT2XhPDfbt-g",
        "outputId": "30898c2e-f7bd-4446-cad1-28971d488dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 30 16:58:55 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    28W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIYe8w-HekH4"
      },
      "source": [
        "Максимум для float16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "2-zo3zx8em--"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros(4096, 927872*2, dtype=torch.float16,device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCDHDFN4etp3",
        "outputId": "eefc0924-d01c-407b-b1dc-59ab425c580f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 30 16:59:45 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    28W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n7YcjKVex6w"
      },
      "source": [
        "Максимум для int32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "zXCmYQN3exaP"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros(4096, 927872, dtype=torch.int32,device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MKqPTDEfH6Q",
        "outputId": "f0469845-e484-47a3-a614-9947bee5b890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 30 17:01:32 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    28W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "w2mDv6eofM9-"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros(4096, 927872//2, dtype=torch.int64,device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evlZb-MMfJ0K",
        "outputId": "6a38950a-a7f1-4ea9-8229-4da3a806064e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 30 17:01:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    28W /  70W |  15106MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Все типы данных занимают по 2, 4, 8 байт, поэтому их размер отличается соответственно в 2, 4, 8 раз"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBR5pWOlzOtl"
      },
      "source": [
        " # **Домашнее задание 4:** \n",
        " Напишите хороший пример неэффективного кода для занятия памяти видеокарты, который вызовет ошибку out of memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "\n",
        "#del a\n",
        "gc.collect()\n",
        "with torch.no_grad():\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec  1 14:47:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 526.98       Driver Version: 526.98       CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   57C    P8     5W /  N/A |    428MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A     14080      C   ...ozlo\\anaconda3\\python.exe    N/A      |\n",
            "|    0   N/A  N/A     15980      C   ...ozlo\\anaconda3\\python.exe    N/A      |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16777216\n",
            "50331648\n",
            "100663296\n",
            "167772160\n",
            "251658240\n",
            "352321536\n",
            "469762048\n",
            "603979776\n",
            "754974720\n",
            "922746880\n",
            "1107296256\n",
            "1308622848\n",
            "1526726656\n",
            "1761607680\n",
            "2013265920\n",
            "2281701376\n",
            "2566914048\n",
            "2868903936\n",
            "3187671040\n",
            "3523215360\n",
            "352321536\n",
            "721420288\n",
            "1107296256\n",
            "1509949440\n",
            "1929379840\n",
            "2365587456\n",
            "2818572288\n",
            "3288334336\n",
            "486539264\n",
            "989855744\n",
            "1509949440\n",
            "2046820352\n",
            "2600468480\n",
            "3170893824\n",
            "587202560\n",
            "1191182336\n",
            "1811939328\n",
            "2449473536\n",
            "3103784960\n",
            "671088640\n",
            "1358954496\n",
            "2063597568\n",
            "2785017856\n",
            "3523215360\n",
            "754974720\n",
            "1526726656\n",
            "2315255808\n",
            "3120562176\n",
            "822083584\n",
            "1660944384\n",
            "2516582400\n",
            "3388997632\n",
            "889192448\n",
            "1795162112\n",
            "2717908992\n",
            "3657433088\n",
            "956301312\n",
            "1929379840\n",
            "2919235584\n",
            "1006632960\n",
            "2030043136\n",
            "3070230528\n",
            "1056964608\n",
            "2130706432\n",
            "3221225472\n",
            "1107296256\n",
            "2231369728\n",
            "3372220416\n",
            "1157627904\n",
            "2332033024\n",
            "3523215360\n",
            "1207959552\n",
            "2432696320\n",
            "3674210304\n",
            "1258291200\n",
            "2533359616\n",
            "1291845632\n",
            "2600468480\n",
            "1325400064\n",
            "2667577344\n",
            "1358954496\n",
            "2734686208\n",
            "1392508928\n",
            "2801795072\n",
            "1426063360\n",
            "2868903936\n",
            "1459617792\n",
            "2936012800\n",
            "1493172224\n",
            "3003121664\n",
            "1526726656\n",
            "3070230528\n",
            "1560281088\n",
            "3137339392\n",
            "1593835520\n",
            "3204448256\n",
            "1627389952\n",
            "3271557120\n",
            "1660944384\n",
            "3338665984\n",
            "1694498816\n",
            "3405774848\n",
            "1728053248\n",
            "3472883712\n",
            "1761607680\n",
            "3539992576\n",
            "1795162112\n",
            "3607101440\n",
            "1828716544\n",
            "3674210304\n",
            "1862270976\n",
            "1879048192\n",
            "1895825408\n",
            "1912602624\n",
            "1929379840\n",
            "1946157056\n",
            "1962934272\n",
            "1979711488\n",
            "1996488704\n",
            "2013265920\n",
            "2030043136\n",
            "2046820352\n",
            "2063597568\n",
            "2080374784\n",
            "2097152000\n",
            "2113929216\n",
            "2130706432\n",
            "2147483648\n",
            "2164260864\n",
            "2181038080\n",
            "2197815296\n",
            "2214592512\n",
            "2231369728\n",
            "2248146944\n",
            "2264924160\n",
            "2281701376\n",
            "2298478592\n",
            "2315255808\n",
            "2332033024\n",
            "2348810240\n",
            "2365587456\n",
            "2382364672\n",
            "2399141888\n",
            "2415919104\n",
            "2432696320\n",
            "2449473536\n",
            "2466250752\n",
            "2483027968\n",
            "2499805184\n",
            "2516582400\n",
            "2533359616\n",
            "2550136832\n",
            "2566914048\n",
            "2583691264\n",
            "2600468480\n",
            "2617245696\n",
            "2634022912\n",
            "2650800128\n",
            "2667577344\n",
            "2684354560\n",
            "2701131776\n",
            "2717908992\n",
            "2734686208\n",
            "2751463424\n",
            "2768240640\n",
            "2785017856\n",
            "2801795072\n",
            "2818572288\n",
            "2835349504\n",
            "2852126720\n",
            "2868903936\n",
            "2885681152\n",
            "2902458368\n",
            "2919235584\n",
            "2936012800\n",
            "2952790016\n",
            "2969567232\n",
            "2986344448\n",
            "3003121664\n",
            "3019898880\n",
            "3036676096\n",
            "3053453312\n",
            "3070230528\n",
            "3087007744\n",
            "3103784960\n",
            "3120562176\n",
            "3137339392\n",
            "3154116608\n",
            "3170893824\n",
            "3187671040\n",
            "3204448256\n",
            "3221225472\n",
            "3238002688\n",
            "3254779904\n",
            "3271557120\n",
            "3288334336\n",
            "3305111552\n",
            "3321888768\n",
            "3338665984\n",
            "3355443200\n",
            "3372220416\n",
            "3388997632\n",
            "3405774848\n",
            "3422552064\n",
            "3439329280\n",
            "3456106496\n",
            "3472883712\n",
            "3489660928\n",
            "3506438144\n",
            "3523215360\n",
            "3539992576\n",
            "3556769792\n",
            "3573547008\n",
            "3590324224\n",
            "3607101440\n",
            "3623878656\n",
            "3640655872\n",
            "3657433088\n",
            "3674210304\n",
            "3690987520\n",
            "3707764736\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA out of memory. Tried to allocate 3.47 GiB (GPU 0; 4.00 GiB total capacity; 0 bytes already allocated; 2.86 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [13], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m----> 8\u001b[0m     a \u001b[39m=\u001b[39m allocate_empty_tensor(i)\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mmemory_reserved())\n\u001b[0;32m     10\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1024\u001b[39m\n",
            "Cell \u001b[1;32mIn [13], line 4\u001b[0m, in \u001b[0;36mallocate_empty_tensor\u001b[1;34m(dim_size)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallocate_empty_tensor\u001b[39m(dim_size):\n\u001b[1;32m----> 4\u001b[0m   a\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mzeros(\u001b[39m4096\u001b[39;49m,dim_size,dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32,device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.47 GiB (GPU 0; 4.00 GiB total capacity; 0 bytes already allocated; 2.86 GiB free; 0 bytes reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def allocate_empty_tensor(dim_size):\n",
        "  a=torch.zeros(4096,dim_size,dtype=torch.float32,device='cuda')\n",
        "\n",
        "i = 1024\n",
        "while True:\n",
        "    a = allocate_empty_tensor(i)\n",
        "    print(torch.cuda.memory_reserved())\n",
        "    i += 1024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_hOtvvR89jq"
      },
      "source": [
        "# **Домашнее задание 5:** \n",
        "Используя один линейный слой `nn.Linear` и один входной тензор `x` подберите подберите размерности так, чтобы занимать всю видеопамять.\n",
        "Попробуйте применить линейный слой к тензору `x`. Что произойдет? Кратко опишите ваши эксперименты. Что вы поняли?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cbJTJaglSjWC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPpBbP8olEvh",
        "outputId": "bfa5c787-0c96-43a4-a20b-e46632513815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ZUkQe6X59t",
        "outputId": "819db55f-51ca-4af9-d2ae-440b94af3aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Dec  1 12:46:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    26W /  70W |  15074MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GmJJKO8zk4Dy"
      },
      "outputs": [],
      "source": [
        "layer = torch.nn.Linear(4096*4096, 225, device = 'cuda')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-zSuFPpjoieI"
      },
      "outputs": [],
      "source": [
        "a=torch.zeros(4096*4096, dtype=torch.float32, device='cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "BJ7mssNxn-eG",
        "outputId": "35b5b632-2998-47e3-bc44-3725694f3c4e"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a51542db94e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasCreate(handle)`"
          ]
        }
      ],
      "source": [
        "res = layer(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Если создавать слой или тензор без параметра `device = 'cuda'`, то он создается сначала в оперативной памяти, а уже после, применяя .cuda() мы переносим его на видеокарту. Поэтому невозможно занять больше памяти, чем есть ОЗУ без параметра device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z2Ot37UODKM"
      },
      "source": [
        "# Рекомендуемые ссылки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnFY95T7kNji"
      },
      "source": [
        "- [Нейронные сети и компьютерное зрение, Samsung AI Center, часть 1](https://stepik.org/course/50352/syllabus)\n",
        "- [Cимулятор](https://playground.tensorflow.org/) нейронов и нейронных сетей"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:41:22) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "cffdd22708c8f24895f497a03a7b67c0092c0fcb40692f19cd97059e00134830"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
