{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat 2 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "img_path = './HKR_dataset/img'\n",
    "ann_path = './HKR_dataset/ann'\n",
    "dst = './dataset'\n",
    "i = 0\n",
    "\n",
    "for ann, img in zip(os.listdir(ann_path), os.listdir(img_path)):\n",
    "    with open(os.path.join(ann_path, ann), 'r', encoding = 'utf-8') as f:\n",
    "        img_ann = json.load(f)['description']\n",
    "    \n",
    "    if i % 7:\n",
    "        dst = './dataset/train'\n",
    "        with open('./dataset/train.tsv', 'a', encoding = 'utf-8') as f:\n",
    "            f.write(f'\\n{img}\\t{img_ann}')\n",
    "    else:\n",
    "        dst = './dataset/test'\n",
    "        with open('./dataset/test.tsv', 'a', encoding = 'utf-8') as f:\n",
    "            f.write(f'\\n{img}\\t{img_ann}')\n",
    "        \n",
    "    shutil.move(os.path.join(img_path, img), os.path.join(dst, img))\n",
    "    i += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./dataset/test.tsv', delimiter='\\t', names = ['Image name', 'Label'])\n",
    "test_alphabet = set(test_df['Label'].to_string())\n",
    "\n",
    "train_df = pd.read_csv('./dataset/train.tsv', delimiter='\\t', names = ['Image name', 'Label'])\n",
    "train_alphabet = set(train_df['Label'].to_string()) - set('\\n')\n",
    "\n",
    "old_train_df = pd.read_csv('./dataset/old_train.tsv', delimiter='\\t', names = ['Image name', 'Label'])\n",
    "old_train_alphabet = set(old_train_df['Label'].to_string()) - set('\\n')\n",
    "\n",
    "print(len(old_train_alphabet))\n",
    "print(train_alphabet == old_train_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted(train_df['Label'].values, key= lambda x: len(x), reverse=True)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reworked dataset. Rm Kazakh symbols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как были объединены 2 датасета, в одном из которых были казахские символы, отредактируем лейблинг, удалив/заменив буквы на русские аналоги. Так же в нем присутствовали ошибочные схожие символы английского алфавита. Все эти корректировки проверялись и редактировались вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_df['Image name'])):\n",
    "    try:\n",
    "        if len(set('ғҚқҮӨө–—…oH') - set(test_df.iloc[i][1])) != len(set('ғҚқҮӨө–—…oH')):\n",
    "            print(test_df.iloc[i][0])\n",
    "    except Exception:\n",
    "        print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполнения функции можно увидеть, что на некоторых картинках не хватает разметки. Дополним эту разметку"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также в данных были и ошибочные метки - ссылка, из-за которой добавлялись английские символы, сокращенный знак кавычек >> или <<. Все эти шумы отфильтровались или заменились на корректные символы"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cffdd22708c8f24895f497a03a7b67c0092c0fcb40692f19cd97059e00134830"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
