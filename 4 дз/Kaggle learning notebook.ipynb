{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:23.486715Z","iopub.status.busy":"2023-02-15T19:53:23.485583Z","iopub.status.idle":"2023-02-15T19:53:37.458282Z","shell.execute_reply":"2023-02-15T19:53:37.456900Z","shell.execute_reply.started":"2023-02-15T19:53:23.486562Z"},"id":"khe7vy_ZwLii","trusted":true},"outputs":[],"source":["#!pip install einops"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:37.461630Z","iopub.status.busy":"2023-02-15T19:53:37.460912Z","iopub.status.idle":"2023-02-15T19:53:39.692389Z","shell.execute_reply":"2023-02-15T19:53:39.691365Z","shell.execute_reply.started":"2023-02-15T19:53:37.461581Z"},"id":"khe7vy_ZwLii","trusted":true},"outputs":[],"source":["import os\n","import torch\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","import wandb\n","\n","from torch import nn\n","from torch import Tensor\n","from PIL import Image\n","from torchvision.transforms import Compose, Resize, ToTensor\n","from einops import rearrange, reduce, repeat\n","from einops.layers.torch import Rearrange, Reduce\n","from tqdm.notebook import tqdm\n","\n","os.environ[\"WANDB_API_KEY\"] = \"c609e6f64c7432a3c19cd118b183a082aef411ee\""]},{"cell_type":"markdown","metadata":{},"source":["# Patch embeddings"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.694915Z","iopub.status.busy":"2023-02-15T19:53:39.693867Z","iopub.status.idle":"2023-02-15T19:53:39.705394Z","shell.execute_reply":"2023-02-15T19:53:39.704141Z","shell.execute_reply.started":"2023-02-15T19:53:39.694873Z"},"trusted":true},"outputs":[],"source":["class PatchEmbedding(nn.Module):\n","    \"\"\" \n","    Image to Patch Embedding\n","    \"\"\"\n","    def __init__(self, img_size=224, patch_size=16, in_chans=3, d_model=768):\n","        super().__init__()\n","        \n","        self.d_model = d_model\n","        self.in_chans = in_chans\n","        self.img_size = img_size\n","        \n","        self.num_patches = (img_size // patch_size) ** 2\n","        self.patch_embeddings = nn.Conv2d(3, self.d_model, patch_size, patch_size)\n","\n","    def forward(self, image):\n","        b, c, h, w = image.shape\n","        \n","        assert h == self.img_size and w == self.img_size, f'Image size must be {self.img_size}x{self.img_size}'\n","        assert c == self.in_chans, f'Image must have {self.in_chans} channels'\n","        \n","        patches = self.patch_embeddings(image).reshape(b, self.d_model, -1).transpose(1, 2)\n","        \n","        return patches"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.709200Z","iopub.status.busy":"2023-02-15T19:53:39.708744Z","iopub.status.idle":"2023-02-15T19:53:39.846472Z","shell.execute_reply":"2023-02-15T19:53:39.845223Z","shell.execute_reply.started":"2023-02-15T19:53:39.709159Z"},"trusted":true},"outputs":[],"source":["x = torch.randn((2, 3, 224, 224))\n","PatchEmbedding()(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Residual block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.848651Z","iopub.status.busy":"2023-02-15T19:53:39.848105Z","iopub.status.idle":"2023-02-15T19:53:39.855674Z","shell.execute_reply":"2023-02-15T19:53:39.854579Z","shell.execute_reply.started":"2023-02-15T19:53:39.848581Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    \n","    def __init__(self, func = None) -> None:\n","        super().__init__()\n","        \n","        self.func = func\n","        if not self.func:\n","            self.func = lambda x: x\n","    \n","    def forward(self, x):\n","        x = self.func(x) + x\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.858051Z","iopub.status.busy":"2023-02-15T19:53:39.857335Z","iopub.status.idle":"2023-02-15T19:53:39.934525Z","shell.execute_reply":"2023-02-15T19:53:39.933440Z","shell.execute_reply.started":"2023-02-15T19:53:39.857995Z"},"trusted":true},"outputs":[],"source":["x = torch.Tensor([1., 2., 3., 4.])\n","ResidualBlock(lambda x: x**2)(x)"]},{"cell_type":"markdown","metadata":{},"source":["# Multi Head Attention Block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.939155Z","iopub.status.busy":"2023-02-15T19:53:39.936002Z","iopub.status.idle":"2023-02-15T19:53:39.949611Z","shell.execute_reply":"2023-02-15T19:53:39.948444Z","shell.execute_reply.started":"2023-02-15T19:53:39.939123Z"},"id":"4QnAW3rSc2OZ","trusted":true},"outputs":[],"source":["class MHABlock(nn.Module):\n","    def __init__(self, emb_len, num_heads=8, attn_drop=0., out_drop=0.):\n","        super().__init__()\n","        \n","        self.num_heads = num_heads # number of heads\n","        head_emb = emb_len // num_heads # embeddings length after head\n","        self.scale = head_emb ** -0.5 # scale param for decrease dispersion\n","\n","        self.qkv = nn.Linear(emb_len, emb_len * 3, bias=False)\n","        self.attn_drop = nn.Dropout(attn_drop)\n","        \n","        self.out = nn.Sequential(\n","            nn.Linear(emb_len, emb_len),\n","            nn.Dropout(out_drop)\n","        )\n","        \n","\n","    def forward(self, x):\n","        \n","        QKV = self.qkv(x)\n","        \"\"\"\n","        b - batch\n","        l - sequence length (number of patches)\n","        n - 3 (Q K V)\n","        h - num heads\n","        hl - seq length after attention\n","        \"\"\"\n","        Q, K, V = rearrange(QKV, 'b l (n h hl) -> n b h l hl', n = 3, h = self.num_heads)\n","\n","        attention = F.softmax(torch.einsum('bhqo, bhko -> bhqk', Q, K) / self.scale, dim=-1)\n","        attention = self.attn_drop(attention)\n","        attention = attention @ V\n","        attention = rearrange(attention, 'b h l hl -> b l (h hl)')\n","        \n","        out = self.out(attention)\n","        return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.953245Z","iopub.status.busy":"2023-02-15T19:53:39.952078Z","iopub.status.idle":"2023-02-15T19:53:40.408196Z","shell.execute_reply":"2023-02-15T19:53:40.406975Z","shell.execute_reply.started":"2023-02-15T19:53:39.953203Z"},"trusted":true},"outputs":[],"source":["x = torch.randn((5, 197, 768))\n","MHABlock(768)(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Feed forward block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.413723Z","iopub.status.busy":"2023-02-15T19:53:40.413301Z","iopub.status.idle":"2023-02-15T19:53:40.426740Z","shell.execute_reply":"2023-02-15T19:53:40.425729Z","shell.execute_reply.started":"2023-02-15T19:53:40.413672Z"},"id":"VPQts2WWdeYQ","trusted":true},"outputs":[],"source":["class FeedForwardBlock(nn.Module):\n","    def __init__(self, in_features, mlp_ratio=4, hidden_features=None, out_features=None, drop_rate=0.):\n","        super().__init__()\n","        \n","        if not hidden_features:\n","            hidden_features = in_features * mlp_ratio\n","        if not out_features:\n","            out_features = in_features\n","\n","        self.linears = nn.Sequential(\n","            nn.Linear(in_features, hidden_features),\n","            nn.GELU(),\n","            nn.Dropout(drop_rate),\n","            nn.Linear(hidden_features, out_features),\n","        )\n","\n","    def forward(self, x):\n","        x = self.linears(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.437004Z","iopub.status.busy":"2023-02-15T19:53:40.434530Z","iopub.status.idle":"2023-02-15T19:53:40.569788Z","shell.execute_reply":"2023-02-15T19:53:40.568670Z","shell.execute_reply.started":"2023-02-15T19:53:40.436952Z"},"id":"LFxxcPoMf7IW","outputId":"c1f44b38-7ec4-4e93-bdb5-a4db4e116e90","trusted":true},"outputs":[],"source":["x = torch.randn(1, 197, 768)\n","FeedForwardBlock(768)(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Encoder block"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.577828Z","iopub.status.busy":"2023-02-15T19:53:40.575104Z","iopub.status.idle":"2023-02-15T19:53:40.590047Z","shell.execute_reply":"2023-02-15T19:53:40.588410Z","shell.execute_reply.started":"2023-02-15T19:53:40.577771Z"},"trusted":true},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(self, emb_len, num_heads=8, mlp_ratio=4, drop_rate=0.):\n","        super().__init__()\n","\n","        self.first_residual = ResidualBlock(\n","            nn.Sequential(\n","                nn.LayerNorm(emb_len),\n","                MHABlock(emb_len, num_heads, drop_rate, drop_rate),\n","                nn.Dropout(drop_rate)\n","            )\n","        )\n","        \n","        self.second_residual = ResidualBlock(\n","            nn.Sequential(\n","                nn.LayerNorm(emb_len),\n","                FeedForwardBlock(emb_len, mlp_ratio),\n","                nn.Dropout(drop_rate)\n","            )\n","        )           \n","\n","    def forward(self, x):\n","        \n","        x = self.first_residual(x)\n","        x = self.second_residual(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.596674Z","iopub.status.busy":"2023-02-15T19:53:40.595841Z","iopub.status.idle":"2023-02-15T19:53:40.759177Z","shell.execute_reply":"2023-02-15T19:53:40.758118Z","shell.execute_reply.started":"2023-02-15T19:53:40.596616Z"},"id":"3aMihgfEhyql","outputId":"993524e8-c7eb-4b38-802e-557e89ba8285","trusted":true},"outputs":[],"source":["x = torch.randn(1, 197, 768)\n","block = EncoderBlock(768, 12)\n","out = block(x)\n","out.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer class. Stack of EncoderBlocks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.761213Z","iopub.status.busy":"2023-02-15T19:53:40.760772Z","iopub.status.idle":"2023-02-15T19:53:40.769568Z","shell.execute_reply":"2023-02-15T19:53:40.768348Z","shell.execute_reply.started":"2023-02-15T19:53:40.761172Z"},"id":"b1uO18VTwLil","trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, num_layers, emb_len, num_heads=8, mlp_ratio=4, drop_rate=0.):\n","        super().__init__()\n","        self.blocks = nn.ModuleList([\n","            EncoderBlock(emb_len, num_heads, mlp_ratio, drop_rate)\n","            for i in range(num_layers)])\n","\n","    def forward(self, x):\n","        for block in self.blocks:\n","            x = block(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.772618Z","iopub.status.busy":"2023-02-15T19:53:40.771264Z","iopub.status.idle":"2023-02-15T19:53:42.589178Z","shell.execute_reply":"2023-02-15T19:53:42.588017Z","shell.execute_reply.started":"2023-02-15T19:53:40.772587Z"},"id":"hIfp984oiBqc","outputId":"704c9a49-92d6-4859-9f61-06555bf89579","trusted":true},"outputs":[],"source":["x = torch.randn(1, 197, 768)\n","Transformer(12, 768)(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Vision Transformer model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:42.591652Z","iopub.status.busy":"2023-02-15T19:53:42.591235Z","iopub.status.idle":"2023-02-15T19:53:42.604317Z","shell.execute_reply":"2023-02-15T19:53:42.603263Z","shell.execute_reply.started":"2023-02-15T19:53:42.591614Z"},"id":"Y9gyxdqQeFs6","trusted":true},"outputs":[],"source":["class ViT(nn.Module):\n","    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n","    \"\"\"\n","    def __init__(self, img_size=224, patch_size=16, in_chans=3, num_classes=1000,\n","                 emb_len=768, num_layers=12, num_heads=12, mlp_ratio=4, drop_rate=0.,):\n","        super().__init__()\n","\n","        # Присвоение переменных\n","        ...\n","\n","        # Path Embeddings, CLS Token, Position Encoding\n","        self.patch_embeddings = PatchEmbedding(img_size, patch_size, in_chans, emb_len)\n","        self.cls_token = nn.Parameter(torch.randn((1, 1, emb_len)))\n","        self.pos_encodings = nn.Parameter(torch.randn((self.patch_embeddings.num_patches + 1, emb_len)))\n","\n","        # Transformer Encoder\n","        self.transformer = Transformer(num_layers, emb_len, num_heads, mlp_ratio, drop_rate)\n","\n","        # Classifier\n","        self.classifier = nn.Linear(emb_len, num_classes)\n","\n","    def forward(self, x):\n","      \n","        # Path Embeddings, CLS Token, Position Encoding\n","        b, c, h, w = x.shape\n","        \n","        cls_tokens = self.cls_token.expand(b, -1, -1)\n","        x = self.pos_encodings + torch.cat((cls_tokens, self.patch_embeddings(x)), dim = 1)\n","\n","        # Transformer Encoder\n","        x = self.transformer(x)[:, 0, :].squeeze(1)\n","\n","        # Classifier\n","        predictions = self.classifier(x)\n","\n","        return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:42.606820Z","iopub.status.busy":"2023-02-15T19:53:42.606340Z","iopub.status.idle":"2023-02-15T19:53:49.574207Z","shell.execute_reply":"2023-02-15T19:53:49.573148Z","shell.execute_reply.started":"2023-02-15T19:53:42.606780Z"},"trusted":true},"outputs":[],"source":["x = torch.randn(10, 3, 224, 224)\n","vit = ViT()\n","out = vit(x)\n","out.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:49.581640Z","iopub.status.busy":"2023-02-15T19:53:49.578655Z","iopub.status.idle":"2023-02-15T19:53:51.205884Z","shell.execute_reply":"2023-02-15T19:53:51.204312Z","shell.execute_reply.started":"2023-02-15T19:53:49.581599Z"},"trusted":true},"outputs":[],"source":["from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","root_train = '../input/vegetable-image-dataset/Vegetable Images/validation'\n","root_test = '../input/vegetable-image-dataset/Vegetable Images/test'\n","transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n","\n","train_data = datasets.ImageFolder(root_train, transform)\n","test_data = datasets.ImageFolder(root_test, transform)\n","\n","train_loader = DataLoader(train_data, 8, True)\n","test_loader = DataLoader(test_data, 8, False)"]},{"cell_type":"markdown","metadata":{},"source":["# Trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:51.207812Z","iopub.status.busy":"2023-02-15T19:53:51.207447Z","iopub.status.idle":"2023-02-15T19:53:51.238405Z","shell.execute_reply":"2023-02-15T19:53:51.237244Z","shell.execute_reply.started":"2023-02-15T19:53:51.207775Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    \n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        optimizer: torch.optim.Optimizer,\n","        scheduler,\n","        dataloader: torch.utils.data.DataLoader,\n","        lossfunc: nn.Module,\n","        epochs: int,\n","        device: str = 'cuda'\n","    ) -> None:\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.scheduler = scheduler\n","        self.dataloader = dataloader\n","        self.lossfunc = lossfunc\n","        self.epochs = epochs\n","        self.device = torch.device(device)\n","    \n","    \n","    def train(self) -> nn.Module:\n","        wandb.watch(self.model, self.lossfunc, log='all', log_freq=100)\n","        \n","        self.model.train()\n","        self.model = self.model.to(self.device)\n","        \n","        for epoch in tqdm(range(1, self.epochs + 1), total=self.epochs):\n","            outputs = []\n","            for (data, targets) in tqdm(self.dataloader, total=len(self.dataloader)):\n","                \n","                loss, acc = self._forward(data, targets)\n","                self._backward(loss)\n","                \n","                outputs.append([loss, acc])\n","            \n","            outputs = torch.Tensor(outputs)\n","            loss, acc = outputs.mean(dim=0).tolist()\n","            lr = self.scheduler.get_last_lr()[-1]\n","            wandb.log({\"acc\": acc, \"loss\": loss, 'Lr': lr})\n","            print(f'Эпоха {epoch}: ', acc, loss, lr)\n","        \n","        return self.model\n","\n","\n","    def _forward(self, data: torch.Tensor, targets: torch.Tensor):\n","        self.optimizer.zero_grad()\n","        \n","        data = data.to(self.device)\n","        targets = targets.to(self.device)\n","        \n","        logits = self.model(data)\n","        \n","        loss = self.lossfunc(logits, targets)\n","        acc = torch.sum(logits.argmax(-1) == targets) / len(logits)\n","        \n","        return loss, acc\n","    \n","\n","\n","    def _backward(self, loss: torch.Tensor) -> None:\n","        loss.backward()\n","        self.optimizer.step()\n","        self.scheduler.step()\n","        "]},{"cell_type":"markdown","metadata":{},"source":["# Tester"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Tester:\n","    \n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        dataloader: torch.utils.data.DataLoader,\n","        device: str = 'cuda'\n","    ) -> None:\n","        self.model = model\n","        self.dataloader = dataloader\n","        self.device = torch.device(device)\n","    \n","    \n","    def test(self) -> nn.Module:\n","        self.model.eval()\n","        self.model = self.model.to(self.device)\n","        \n","        outputs = []\n","        for (data, targets) in tqdm(self.dataloader, total=len(self.dataloader)):\n","            \n","            acc = self._forward(data, targets)\n","            outputs.append([acc])\n","        \n","        outputs = torch.Tensor(outputs)\n","        acc = outputs.mean(dim=0).item()\n","        wandb.log({\"Test acc\": acc})\n","        print('Test accuracy: ', acc)\n","        \n","\n","    def _forward(self, data: torch.Tensor, targets: torch.Tensor):\n","        data = data.to(self.device)\n","        targets = targets.to(self.device)\n","        \n","        logits = self.model(data)\n","        acc = torch.sum(logits.argmax(-1) == targets) / len(logits)\n","        \n","        return acc"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["patch_size = 32\n","num_heads = 16\n","emb_len = 768\n","drop_rate = 0.2\n","max_lr = 0.0002\n","epochs = 200"]},{"cell_type":"markdown","metadata":{},"source":["# WandB"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Initializing WANDB...')\n","wandb.init(\n","        project=\"First ViT\",\n","        name = f\"P_{patch_size}-H_{num_heads}-E_{emb_len}-D_{drop_rate}-LR_{max_lr}\",\n","        config={\n","            'Model': 'Transformer',\n","            'Optimizer': 'Adam',\n","            'Scheduler': 'OneCycleLR',\n","            'architecture': 'RCNN',\n","            'dataset': 'Custom dataset',\n","            'epochs': epochs,\n","        }\n","    )\n","print('Initializing succsessful...')"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:54:48.406209Z","iopub.status.busy":"2023-02-15T19:54:48.405778Z","iopub.status.idle":"2023-02-15T20:44:51.805054Z","shell.execute_reply":"2023-02-15T20:44:51.803831Z","shell.execute_reply.started":"2023-02-15T19:54:48.406173Z"},"trusted":true},"outputs":[],"source":["print('Initializing model...')\n","model = ViT(patch_size=patch_size,\n","            num_heads=num_heads,\n","            emb_len=emb_len,\n","            num_classes=15,\n","            drop_rate=drop_rate)\n","\n","optim = torch.optim.Adam(model.parameters())\n","loss = nn.CrossEntropyLoss()\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optim,\n","                                                total_steps=epochs*len(train_loader),\n","                                                pct_start=0.2,\n","                                                max_lr=max_lr)\n","trainer = Trainer(model, optim, scheduler, train_loader, loss, epochs)\n","print('Init succsessful')"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Start training')\n","model = trainer.train()\n","print('Training is finished')"]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tester = Tester(model, test_loader)\n","tester.test()"]},{"cell_type":"markdown","metadata":{},"source":["# Saving model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T21:00:17.687201Z","iopub.status.busy":"2023-02-15T21:00:17.686821Z","iopub.status.idle":"2023-02-15T21:00:18.475375Z","shell.execute_reply":"2023-02-15T21:00:18.473919Z","shell.execute_reply.started":"2023-02-15T21:00:17.687166Z"},"trusted":true},"outputs":[],"source":["torch.save(model.state_dict(), 'Transformer.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wandb.finish()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
