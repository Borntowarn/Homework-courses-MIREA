{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:23.486715Z","iopub.status.busy":"2023-02-15T19:53:23.485583Z","iopub.status.idle":"2023-02-15T19:53:37.458282Z","shell.execute_reply":"2023-02-15T19:53:37.456900Z","shell.execute_reply.started":"2023-02-15T19:53:23.486562Z"},"id":"khe7vy_ZwLii","trusted":true},"outputs":[],"source":["#!pip install einops"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:37.461630Z","iopub.status.busy":"2023-02-15T19:53:37.460912Z","iopub.status.idle":"2023-02-15T19:53:39.692389Z","shell.execute_reply":"2023-02-15T19:53:39.691365Z","shell.execute_reply.started":"2023-02-15T19:53:37.461581Z"},"id":"khe7vy_ZwLii","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Global seed set to 0\n"]}],"source":["import os\n","import torch\n","import wandb\n","import pytorch_lightning as pl\n","import torch.nn.functional as F\n","\n","\n","from torch import nn\n","from typing import *\n","from einops import rearrange\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.loggers import WandbLogger\n","from pytorch_lightning.tuner.tuning import Tuner\n","\n","torch.random.manual_seed(0)\n","pl.seed_everything(0)"]},{"cell_type":"markdown","metadata":{},"source":["# Patch embeddings"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.694915Z","iopub.status.busy":"2023-02-15T19:53:39.693867Z","iopub.status.idle":"2023-02-15T19:53:39.705394Z","shell.execute_reply":"2023-02-15T19:53:39.704141Z","shell.execute_reply.started":"2023-02-15T19:53:39.694873Z"},"trusted":true},"outputs":[],"source":["class PatchEmbedding(nn.Module):\n","    \"\"\" \n","    Image to Patch Embedding\n","    \"\"\"\n","    def __init__(\n","        self,\n","        img_size: int = 224,\n","        patch_size: int = 16,\n","        in_chans: int = 3,\n","        d_model: int = 768\n","    ):\n","        super().__init__()\n","        \n","        self.d_model = d_model\n","        self.in_chans = in_chans\n","        self.img_size = img_size\n","        \n","        self.num_patches = (img_size // patch_size) ** 2\n","        self.patch_embeddings = nn.Conv2d(3, self.d_model, patch_size, patch_size)\n","\n","    def forward(self, image):\n","        b, c, h, w = image.shape\n","        \n","        assert h == self.img_size and w == self.img_size, f'Image size must be {self.img_size}x{self.img_size}'\n","        assert c == self.in_chans, f'Image must have {self.in_chans} channels'\n","        \n","        patches = self.patch_embeddings(image).reshape(b, self.d_model, -1).transpose(1, 2)\n","        \n","        return patches"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.709200Z","iopub.status.busy":"2023-02-15T19:53:39.708744Z","iopub.status.idle":"2023-02-15T19:53:39.846472Z","shell.execute_reply":"2023-02-15T19:53:39.845223Z","shell.execute_reply.started":"2023-02-15T19:53:39.709159Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([2, 196, 768])"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn((2, 3, 224, 224))\n","PatchEmbedding()(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Residual block"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.848651Z","iopub.status.busy":"2023-02-15T19:53:39.848105Z","iopub.status.idle":"2023-02-15T19:53:39.855674Z","shell.execute_reply":"2023-02-15T19:53:39.854579Z","shell.execute_reply.started":"2023-02-15T19:53:39.848581Z"},"trusted":true},"outputs":[],"source":["class ResidualBlock(nn.Module):\n","    \n","    def __init__(self, func: Optional[Callable] = None) -> None:\n","        super().__init__()\n","        \n","        self.func = func\n","        if not self.func:\n","            self.func = lambda x: x\n","    \n","    def forward(self, x):\n","        x = self.func(x) + x\n","        return x"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.858051Z","iopub.status.busy":"2023-02-15T19:53:39.857335Z","iopub.status.idle":"2023-02-15T19:53:39.934525Z","shell.execute_reply":"2023-02-15T19:53:39.933440Z","shell.execute_reply.started":"2023-02-15T19:53:39.857995Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 2.,  6., 12., 20.])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.Tensor([1., 2., 3., 4.])\n","ResidualBlock(lambda x: x**2)(x)"]},{"cell_type":"markdown","metadata":{},"source":["# Multi Head Attention Block"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.939155Z","iopub.status.busy":"2023-02-15T19:53:39.936002Z","iopub.status.idle":"2023-02-15T19:53:39.949611Z","shell.execute_reply":"2023-02-15T19:53:39.948444Z","shell.execute_reply.started":"2023-02-15T19:53:39.939123Z"},"id":"4QnAW3rSc2OZ","trusted":true},"outputs":[],"source":["class MHABlock(nn.Module):\n","    def __init__(\n","        self,\n","        emb_len: int,\n","        num_heads: int = 8,\n","        attn_drop: float = 0.,\n","        out_drop: float = 0.\n","    ):\n","        super().__init__()\n","        \n","        self.num_heads = num_heads # number of heads\n","        head_emb = emb_len // num_heads # embeddings length after head\n","        self.scale = head_emb ** -0.5 # scale param for decrease dispersion\n","\n","        self.qkv = nn.Linear(emb_len, emb_len * 3, bias=False)\n","        self.attn_drop = nn.Dropout(attn_drop)\n","        \n","        self.out = nn.Sequential(\n","            nn.Linear(emb_len, emb_len),\n","            nn.Dropout(out_drop)\n","        )\n","        \n","\n","    def forward(self, x):\n","        \n","        QKV = self.qkv(x)\n","        \"\"\"\n","        b - batch\n","        l - sequence length (number of patches)\n","        n - 3 (Q K V)\n","        h - num heads\n","        hl - seq length after attention\n","        \"\"\"\n","        Q, K, V = rearrange(QKV, 'b l (n h hl) -> n b h l hl', n = 3, h = self.num_heads)\n","\n","        attention = F.softmax(torch.einsum('bhqo, bhko -> bhqk', Q, K) / self.scale, dim=-1)\n","        attention = self.attn_drop(attention)\n","        attention = attention @ V\n","        attention = rearrange(attention, 'b h l hl -> b l (h hl)')\n","        \n","        out = self.out(attention)\n","        return out\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:39.953245Z","iopub.status.busy":"2023-02-15T19:53:39.952078Z","iopub.status.idle":"2023-02-15T19:53:40.408196Z","shell.execute_reply":"2023-02-15T19:53:40.406975Z","shell.execute_reply.started":"2023-02-15T19:53:39.953203Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([5, 197, 768])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn((5, 197, 768))\n","MHABlock(768)(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Feed forward block"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.413723Z","iopub.status.busy":"2023-02-15T19:53:40.413301Z","iopub.status.idle":"2023-02-15T19:53:40.426740Z","shell.execute_reply":"2023-02-15T19:53:40.425729Z","shell.execute_reply.started":"2023-02-15T19:53:40.413672Z"},"id":"VPQts2WWdeYQ","trusted":true},"outputs":[],"source":["class FeedForwardBlock(nn.Module):\n","    def __init__(\n","        self, \n","        in_features: int, \n","        mlp_ratio: int = 4,\n","        hidden_features: Optional[int] = None, \n","        out_features: Optional[int] = None, \n","        drop_rate: float = 0.\n","    ):\n","        super().__init__()\n","        \n","        if not hidden_features:\n","            hidden_features = in_features * mlp_ratio\n","        if not out_features:\n","            out_features = in_features\n","\n","        self.linears = nn.Sequential(\n","            nn.Linear(in_features, hidden_features),\n","            nn.GELU(),\n","            nn.Dropout(drop_rate),\n","            nn.Linear(hidden_features, out_features),\n","        )\n","\n","    def forward(self, x):\n","        x = self.linears(x)\n","        return x"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.437004Z","iopub.status.busy":"2023-02-15T19:53:40.434530Z","iopub.status.idle":"2023-02-15T19:53:40.569788Z","shell.execute_reply":"2023-02-15T19:53:40.568670Z","shell.execute_reply.started":"2023-02-15T19:53:40.436952Z"},"id":"LFxxcPoMf7IW","outputId":"c1f44b38-7ec4-4e93-bdb5-a4db4e116e90","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 197, 768])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(1, 197, 768)\n","FeedForwardBlock(768)(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Encoder block"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.577828Z","iopub.status.busy":"2023-02-15T19:53:40.575104Z","iopub.status.idle":"2023-02-15T19:53:40.590047Z","shell.execute_reply":"2023-02-15T19:53:40.588410Z","shell.execute_reply.started":"2023-02-15T19:53:40.577771Z"},"trusted":true},"outputs":[],"source":["class EncoderBlock(nn.Module):\n","    def __init__(\n","        self, \n","        emb_len: int, \n","        num_heads: int = 8, \n","        mlp_ratio: int = 4, \n","        drop_rate: float = 0.\n","    ):\n","        super().__init__()\n","\n","        self.first_residual = ResidualBlock(\n","            nn.Sequential(\n","                nn.LayerNorm(emb_len),\n","                MHABlock(emb_len, num_heads, drop_rate, drop_rate),\n","                nn.Dropout(drop_rate)\n","            )\n","        )\n","        \n","        self.second_residual = ResidualBlock(\n","            nn.Sequential(\n","                nn.LayerNorm(emb_len),\n","                FeedForwardBlock(emb_len, mlp_ratio),\n","                nn.Dropout(drop_rate)\n","            )\n","        )           \n","\n","    def forward(self, x):\n","        \n","        x = self.first_residual(x)\n","        x = self.second_residual(x)\n","        \n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.596674Z","iopub.status.busy":"2023-02-15T19:53:40.595841Z","iopub.status.idle":"2023-02-15T19:53:40.759177Z","shell.execute_reply":"2023-02-15T19:53:40.758118Z","shell.execute_reply.started":"2023-02-15T19:53:40.596616Z"},"id":"3aMihgfEhyql","outputId":"993524e8-c7eb-4b38-802e-557e89ba8285","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 197, 768])"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(1, 197, 768)\n","block = EncoderBlock(768, 12)\n","out = block(x)\n","out.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Transformer class. Stack of EncoderBlocks"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.761213Z","iopub.status.busy":"2023-02-15T19:53:40.760772Z","iopub.status.idle":"2023-02-15T19:53:40.769568Z","shell.execute_reply":"2023-02-15T19:53:40.768348Z","shell.execute_reply.started":"2023-02-15T19:53:40.761172Z"},"id":"b1uO18VTwLil","trusted":true},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(\n","        self, \n","        num_layers: int, \n","        emb_len: int, \n","        num_heads: int = 12,\n","        mlp_ratio: int = 4,\n","        drop_rate: float = 0.\n","    ):\n","        super().__init__()\n","        self.blocks = nn.ModuleList([\n","            EncoderBlock(emb_len, num_heads, mlp_ratio, drop_rate)\n","            for i in range(num_layers)])\n","\n","    def forward(self, x):\n","        for block in self.blocks:\n","            x = block(x)\n","        return x"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:40.772618Z","iopub.status.busy":"2023-02-15T19:53:40.771264Z","iopub.status.idle":"2023-02-15T19:53:42.589178Z","shell.execute_reply":"2023-02-15T19:53:42.588017Z","shell.execute_reply.started":"2023-02-15T19:53:40.772587Z"},"id":"hIfp984oiBqc","outputId":"704c9a49-92d6-4859-9f61-06555bf89579","trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([1, 197, 768])"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(1, 197, 768)\n","Transformer(12, 768)(x).shape"]},{"cell_type":"markdown","metadata":{},"source":["# Vision Transformer model"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["class ViT(pl.LightningModule):\n","  \n","    def __init__(\n","        self,\n","        img_size: int = 224,\n","        patch_size: int = 16,\n","        in_chans: int = 3,\n","        num_classes: int = 1000,\n","        emb_len: int = 768,\n","        num_layers: int = 12,\n","        num_heads: int = 12,\n","        mlp_ratio: int = 4,\n","        drop_rate: int = 0.,\n","        loss_func = None\n","    ):\n","        super(ViT, self).__init__()\n","        self.save_hyperparameters(ignore=['loss_func'])\n","        \n","        # Path Embeddings, CLS Token, Position Encoding\n","        self.patch_embeddings = PatchEmbedding(img_size, patch_size, in_chans, emb_len)\n","        self.cls_token = nn.Parameter(torch.randn((1, 1, emb_len)))\n","        self.pos_encodings = nn.Parameter(torch.randn((self.patch_embeddings.num_patches + 1, emb_len)))\n","\n","        # Transformer Encoder\n","        self.transformer = Transformer(num_layers, emb_len, num_heads, mlp_ratio, drop_rate)\n","\n","        # Classifier\n","        self.classifier = nn.Linear(emb_len, num_classes)\n","        \n","        self.loss_func = loss_func\n","\n","\n","    def forward(self, x):\n","        # Path Embeddings, CLS Token, Position Encoding\n","        b, c, h, w = x.shape\n","        \n","        cls_tokens = self.cls_token.expand(b, -1, -1)\n","        x = self.pos_encodings + torch.cat((cls_tokens, self.patch_embeddings(x)), dim = 1)\n","\n","        # Transformer Encoder\n","        x = self.transformer(x)[:, 0, :].squeeze(1)\n","\n","        # Classifier\n","        predictions = self.classifier(x)\n","\n","        return predictions\n","\n","\n","    # Настраиваются параметры обучения\n","    def training_step(self, batch, batch_idx):\n","        data, targets = batch\n","        logits = self(data)\n","        \n","        loss = self.loss_func(logits, targets)\n","        accuracy = torch.sum(logits.argmax(-1) == targets) / len(logits)\n","        \n","        lr = self.lr_schedulers().get_last_lr()[-1]\n","        self.log('loss', loss, on_epoch=True, on_step=False)\n","        self.log('acc', accuracy, on_epoch=True, on_step=False)\n","        self.log('Lr', lr, on_epoch=True, on_step=False)\n","        \n","        output = {\n","            'loss': loss,\n","            'acc': accuracy,\n","            'lr': lr\n","        }\n","        \n","        return output\n","\n","\n","    # Настраиваются параметры тестирования\n","    def test_step(self, batch, batch_idx):\n","        data, targets = batch\n","        logits = self(data)\n","        \n","        loss = self.loss_func(logits, targets)\n","        accuracy = torch.sum(logits.argmax(-1) == targets) / len(logits)\n","    \n","        self.log('Test acc', accuracy, prog_bar=True) \n","        output = {\n","            'loss': loss,\n","            'acc': accuracy\n","        }\n","        return output\n","\n","\n","    # Конфигурируется оптимизатор\n","    def configure_optimizers(self):\n","        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)\n","        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n","            optimizer, \n","            max_lr = 0.0004,\n","            total_steps = self.trainer.max_epochs * self.trainer.datamodule.len_train_dataloader,\n","            pct_start=0.1)\n","        \n","        config = {\n","            'optimizer': optimizer,\n","            'lr_scheduler': {\n","                'scheduler': scheduler,\n","                'interval': 'step'\n","            }\n","        }\n","\n","        return config\n","\n","    def training_epoch_end(self, outputs) -> None:\n","        loss = sum(output['loss'] for output in outputs) / len(outputs)\n","        print(f'Эпоха {self.current_epoch}, loss = {loss}')"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:53:42.606820Z","iopub.status.busy":"2023-02-15T19:53:42.606340Z","iopub.status.idle":"2023-02-15T19:53:49.574207Z","shell.execute_reply":"2023-02-15T19:53:49.573148Z","shell.execute_reply.started":"2023-02-15T19:53:42.606780Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([10, 15])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.randn(10, 3, 224, 224)\n","vit = ViT(num_classes=15)\n","out = vit(x)\n","out.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["class DataModule(pl.LightningDataModule):\n","    \n","    \n","    def __init__(\n","        self,\n","        root_dir: str,\n","        train_folder: str,\n","        test_folder: str,\n","        batch_size: int\n","    ) -> None:\n","        super(pl.LightningDataModule, self).__init__()\n","        \n","        self.train_dir = os.path.join(root_dir, train_folder)\n","        self.test_dir = os.path.join(root_dir, test_folder)\n","        \n","        self.transform = transforms.Compose([\n","            transforms.Resize((224, 224)), \n","            transforms.ToTensor()])\n","        \n","        self.batch_size = batch_size\n","    \n","    \n","    def setup(self, stage: Optional[str] = None) -> None:\n","        if stage == 'fit':\n","            self.train_data = datasets.ImageFolder(self.train_dir, self.transform)\n","            self.len_train_dataloader = len(self.train_data) // self.batch_size\n","        if stage == 'test':\n","            self.test_data = datasets.ImageFolder(self.test_dir, self.transform)\n","    \n","    \n","    def train_dataloader(self) -> DataLoader:\n","        return DataLoader(self.train_data, self.batch_size, True, drop_last=True)\n","\n","    \n","    def test_dataloader(self) -> DataLoader:\n","        return DataLoader(self.test_data, self.batch_size, False, drop_last=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Config"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["patch_size = 16\n","num_heads = 8\n","num_layers = 8\n","emb_len = 384\n","drop_rate = 0.07\n","max_lr = 0.0004\n","epochs = 400\n","root_dir = './dataset'\n","name = f\"P_{patch_size}-H_{num_heads}-L_{num_layers}-E_{emb_len}-D_{drop_rate}-LR_{max_lr}-Epochs_{epochs}\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Init modules"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-02-15T19:54:48.406209Z","iopub.status.busy":"2023-02-15T19:54:48.405778Z","iopub.status.idle":"2023-02-15T20:44:51.805054Z","shell.execute_reply":"2023-02-15T20:44:51.803831Z","shell.execute_reply.started":"2023-02-15T19:54:48.406173Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Initializing modules...\n"]},{"name":"stderr","output_type":"stream","text":["GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n"]},{"name":"stdout","output_type":"stream","text":["Initializing successful...\n"]}],"source":["print('Initializing modules...')\n","\n","model = ViT(loss_func=nn.CrossEntropyLoss())\n","datamodule = DataModule(root_dir, 'validation', 'test', 8)\n","\n","#wandb_logger = WandbLogger(project = \"First ViT\", log_model = True, name=name)\n","#wandb_logger.watch(model, log = 'all', log_freq=100)\n","\n","trainer = pl.Trainer(\n","    accelerator = 'gpu',\n","    max_epochs = epochs,\n","    default_root_dir = './lightning'\n","    #logger = wandb_logger,\n",")\n","print('Initializing successful...')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Tune batch size"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","`Trainer.fit` stopped: `max_steps=5` reached.\n","Batch size 2 succeeded, trying batch size 4\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","`Trainer.fit` stopped: `max_steps=5` reached.\n","Batch size 4 succeeded, trying batch size 8\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","`Trainer.fit` stopped: `max_steps=5` reached.\n","Batch size 8 succeeded, trying batch size 16\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Batch size 16 failed, trying batch size 12\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Batch size 12 failed, trying batch size 10\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Batch size 10 failed, trying batch size 9\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","`Trainer.fit` stopped: `max_steps=5` reached.\n","Finished batch size finder, will continue with full run using batch size 9\n","Restoring states from the checkpoint path at lightning\\.scale_batch_size_e4ef35f3-1d16-45c5-86de-63fc2fa8db04.ckpt\n"]}],"source":["tuner = Tuner(trainer)\n","new_batch_size = tuner.scale_batch_size(model, datamodule=datamodule, steps_per_trial=5, mode=\"binsearch\")"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Start training\n"]},{"name":"stderr","output_type":"stream","text":["LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","  | Name             | Type             | Params\n","------------------------------------------------------\n","0 | patch_embeddings | PatchEmbedding   | 590 K \n","1 | transformer      | Transformer      | 85.0 M\n","2 | classifier       | Linear           | 769 K \n","3 | loss_func        | CrossEntropyLoss | 0     \n","------------------------------------------------------\n","86.5 M    Trainable params\n","0         Non-trainable params\n","86.5 M    Total params\n","346.154   Total estimated model params size (MB)\n","c:\\Users\\kozlo\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e072eca484244e628c713cc1b968306f","version_major":2,"version_minor":0},"text/plain":["Training: 0it [00:00, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Эпоха 0, loss = 3.007328748703003\n","Эпоха 1, loss = 2.4439785480499268\n","Эпоха 2, loss = 2.1970081329345703\n","Эпоха 3, loss = 2.0362391471862793\n","Training is finished\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\kozlo\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n","  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"]}],"source":["print('Start training')\n","trainer.fit(model, datamodule)\n","print('Training is finished')"]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Start testing')\n","trainer.test(model, datamodule)\n","print('Testing is finished')"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.15"},"vscode":{"interpreter":{"hash":"cffdd22708c8f24895f497a03a7b67c0092c0fcb40692f19cd97059e00134830"}}},"nbformat":4,"nbformat_minor":4}
