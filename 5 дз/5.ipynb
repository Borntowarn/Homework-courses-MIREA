{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Squeeze-and-Excitation (SE) block proposed in [1].\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of channels in the input tensor.\n",
    "    reduction : int, optional, default=16\n",
    "        Reduction ratio to control the intermediate channel dimension.\n",
    "    References\n",
    "    ----------\n",
    "    1. \"`Squeeze-and-Excitation Networks. <https://arxiv.org/abs/1709.01507>`_\" Jie Hu, et al. CVPR 2018.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        reduction: int = 16\n",
    "    ) -> None:\n",
    "        super(SEBlock, self).__init__()\n",
    "\n",
    "        out_channels = in_channels // reduction\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, in_channels, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor (batch_size, in_channels, height, width)\n",
    "            Input tensor.\n",
    "        Returns\n",
    "        -------\n",
    "        out : torch.Tensor (batch_size, in_channels, height, width)\n",
    "            Output of the SK convolution layer.\n",
    "        \"\"\"\n",
    "        # x: [b, c, h, w]\n",
    "\n",
    "        z = self.squeeze(x)\n",
    "        s = self.excitation(z)\n",
    "        out =  x * s\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 25, 25])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.rand(1, 32, 25, 25)\n",
    "out = SEBlock(32)\n",
    "out(features).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import List, Optional\n",
    "from einops import rearrange\n",
    "\n",
    "class SKConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of the Selective Kernel (SK) Convolution proposed in [1].\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of channels in the input tensor.\n",
    "    out_channels : int\n",
    "        Number of channels produced by the convolution.\n",
    "    kernels : List[int], optional, default=[3, 5]\n",
    "        List of kernel sizes for each branch.\n",
    "    reduction : int, optional, default=16\n",
    "        Reduction ratio to control the dimension of \"compact feature\" ``z`` (see eq.4).\n",
    "    L : int, optional, default=32\n",
    "        Minimal value of the dimension of \"compact feature\" ``z`` (see eq.4).\n",
    "    groups : int, optional, default=32\n",
    "        Hyperparameter for ``torch.nn.Conv2d``.\n",
    "    References\n",
    "    ----------\n",
    "    1. \"`Selective Kernel Networks. <https://arxiv.org/abs/1903.06586>`_\" Xiang Li, et al. CVPR 2019.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: Optional[int] = None,\n",
    "        kernels: List[int] = [3, 5],\n",
    "        reduction: int = 16,\n",
    "        L: int = 32,\n",
    "        groups: int = 32\n",
    "    ) -> None:\n",
    "        super(SKConv, self).__init__()\n",
    "\n",
    "        if out_channels is None:\n",
    "            out_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        d = max([in_channels // reduction, L])\n",
    "\n",
    "        self.M = len(kernels)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    dilation=k//2,\n",
    "                    padding=k//2\n",
    "                ),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "            for k in kernels\n",
    "        ])\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.fc_z = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, d, 1, 1),\n",
    "            nn.BatchNorm2d(d),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "        self.fc_attn = nn.Conv2d(d, out_channels * self.M, 1)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor (batch_size, in_channels, height, width)\n",
    "            Input tensor.\n",
    "        Returns\n",
    "        -------\n",
    "        out : torch.Tensor (batch_size, out_channels, height, width)\n",
    "            Output of the SK convolution layer.\n",
    "        \"\"\"\n",
    "        #Conv2d , AvgPoll, softmax, ReLU, BatchNorm, Linear\n",
    "\n",
    "        # ----- split -----\n",
    "        # x: [b, c, h, w]\n",
    "        feats = torch.cat(tuple(conv(x).unsqueeze(1) for conv in self.convs), dim=1) # [b, M, c, h, w]\n",
    "\n",
    "        # ----- fuse -----\n",
    "        # eq.1\n",
    "        U = torch.sum(feats, dim = 1)\n",
    "        # channel-wise statistics, eq.2\n",
    "        s = self.pool(U)  #s: [b, c]\n",
    "        # compact feature, eq.3\n",
    "        z = self.fc_z(s) # z [b, d]\n",
    "\n",
    "        # ----- select -----\n",
    "        batch_size, out_channels = s.shape[:2]\n",
    "\n",
    "        # attention map, eq.5\n",
    "        score = self.fc_attn(z)  # (batch_size, M * out_channels)\n",
    "        score = rearrange(score, 'b (M C) 1 1-> b M C 1 1', M = self.M)  # (batch_size, M, out_channels, 1, 1)\n",
    "        att = self.softmax(score)\n",
    "\n",
    "\n",
    "        # fuse multiple branches, eq.6\n",
    "        out = torch.sum(feats * att, dim = 1)  # (batch_size, out_channels, height, width)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 544, 25, 25])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = torch.rand(2, 34*16, 25, 25)\n",
    "out = SKConv(34*16).eval()\n",
    "out(features).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
